For our project, our proposed solution was to implement different prediction algorithms (Random Forest and LSTM) on the dataset to be able to view how the predicted results look like for the probability of a disaster occuring, the probability of a disaster occuring a region based on time of year and probability of obtaining funding for specific disasters based on historical data. 

Random Forest in this scenario is being used as a classification algorithm since many of the target variables have binary values to demonstrate if a specific disaster has happened or not. Since it is also being trained on labeled data, this is supervised learning because it is using known outputs to make predictions. 

Random forest classification is an algorithm that uses many decision trees to make more reliable predictions based on considering all the various factors and then choose the prediction with the majority vote (in classification). Each tree can be sampled on a random sample of the dataset and each time, only a random variety of features are taken into consideration.  This helps avoid mistakes and gives more accurate results by doing more through testing on the training data. Since this model just predicts the month and region with disaster, it provides a general disaster risk for a month in the future.

As a result, for this prediction, we use Random Forest Classification because disasters are typically more complicated and based on various factors like location, season and previous patterns. Since this dataset has many features/is very dimensional, random forest greatly assists with this. It also handles unbalanced data (such as some disasters which may occur less than others, which means they appear less in the dataset but does not necessarily mean they are not as bad). Random forest takes this class balance into account and we added balanced weights for the classes to help in this scenario. Also since disasters are not often perfectly linear situations but more complex, these details can be handled well by this sort of algorithm and its feature importance. 

In the code specifically it first loads the data (DisasterDeclarationSummariesPlusLocation_RowColFiltered.csv) which was already preprocessed to focus on specific water based disasters. Then based on the month, it adds a specific season that correlates to that "bin" and a region based on its longitude/latitude location with one hot encoding. The month is implemented with the sine/cosine functionality since months are cyclical (ex: Jan is similar to Dec and Feb since they are all considered winter months). We want to ensure that instead of just using the numerical values for the months then it will be seen as linear not cyclical (month 1 is close to month 12 but if linear it will be seen as further apart). Therefore by converting these into sine and cosine we can get the position of the month in a sine/cosine wave format (ex: June will be opposite end of cycle because it is peak but Jan and Dec will be the same level as they are winter months). This really helps with pattern recognition as well.

The algorithm then trains a Random Forest model for each disaster type and also implements Stratified K-fold Cross Validation to ensure there is an even distribution present of various classes within training and testing. It also trains the Random Forest with class_weight = balanced to handle class imbalances as discussed above. The class weight helps the model pay more attention to rare classes.  We then also see the probability of certain disasters occuring in addition to their accuracy, F1 score, recall and precision which is really important to get a holistic view of what is occuring. We also implemented hyperparameters to help ensure that the model is trained on various different features including: how deep the trees can grow, how many trees are built, and how features are selected during training. These are built in features into RandomForest that greatly assist with this classification process and are important to product robustness

Then, we are creating a regional dataframe called regional predictions to collect the probabilities based on the different factors we are taking into account and adding to the data. We create bar charts to compare disaster risks across various regions (showing avg probability) while the heatmaps also implement the seasons and the avg disaster probability for each region during a specific season. 
